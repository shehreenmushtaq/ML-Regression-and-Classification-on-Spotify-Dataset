{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group 19 (CS986FoMLDAGroup19)\n",
    "#### Kaggle Team: Straw-hat Pirates\n",
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spotify Classification: predict the top genre that a song belongs to.  \n",
    "\n",
    "This dataset includes these features:  \n",
    "**Id**: unique track identifier.  \n",
    "**title**: track title.  \n",
    "**artist**: singer or band.  \n",
    "**year**:  year of release (or re-release).  \n",
    "**bpm**:  beats per minute.  \n",
    "**nrgy**:  energy: higher, more energetic.  \n",
    "**dnce**: danceability: higher, the easier to dance to.  \n",
    "**dB**:  loudness (dB): the higher the value, the louder the song.  \n",
    "**live**: liveness: higher, more likely it's a live recording.  \n",
    "**val**: valence: higher, more positive mood.  \n",
    "**dur**: duration: song length.  \n",
    "**acous**: acousticness: higher, more acoustic.  \n",
    "**spch**: speechiness: higher, more spoken word.  \n",
    "**pop**:  popularity: higher is more popular.  \n",
    "**top genre**:  genre of the track (class label).  \n",
    "\n",
    "Spotify: https://developer.spotify.com/documentation/web-api/reference/#/operations/get-audio-features\n",
    "\n",
    "Kaggle Data: https://www.kaggle.com/cnic92/spotify-past-decades-songs-50s10s  \n",
    "The training dataset contains 453 rows Ã— 15 columns including the Id column. There are 13 column attributes in the dataset that can be used to build a model that predicts \"top genre\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# plotting\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "Load the train and Kaggle test data:\n",
    "the train data will be split into train and validation sets\n",
    "for hyperparameter tuning and to select the best model. \n",
    "The best model will be trained on the entire training set\n",
    "and used to make predictions using the test set for submission\n",
    "to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T21:57:13.047780Z",
     "iopub.status.busy": "2023-02-18T21:57:13.047288Z",
     "iopub.status.idle": "2023-02-18T21:57:13.061887Z",
     "shell.execute_reply": "2023-02-18T21:57:13.060828Z",
     "shell.execute_reply.started": "2023-02-18T21:57:13.047734Z"
    }
   },
   "outputs": [],
   "source": [
    "on_kaggle=False  # option to work on Kaggle or locally on laptop\n",
    "\n",
    "if on_kaggle:\n",
    "    dataset=pd.read_csv('/kaggle/input/cs9856-spotify-classification-problem-2023/CS98XClassificationTrain.csv')\n",
    "    test_dataset=pd.read_csv(\"/kaggle/input/cs9856-spotify-classification-problem-2023/CS98XClassificationTest.csv\")\n",
    "else:\n",
    "    dataset=pd.read_csv('CS98XClassificationTrain.csv')\n",
    "    test_dataset=pd.read_csv(\"CS98XClassificationTest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T21:57:13.064624Z",
     "iopub.status.busy": "2023-02-18T21:57:13.063580Z",
     "iopub.status.idle": "2023-02-18T21:57:13.069603Z",
     "shell.execute_reply": "2023-02-18T21:57:13.068344Z",
     "shell.execute_reply.started": "2023-02-18T21:57:13.064582Z"
    },
    "id": "QGZp4N-8w1YO"
   },
   "outputs": [],
   "source": [
    "train_dataset = dataset.copy()\n",
    "test_df = test_dataset.copy() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA and Visualization\n",
    "\n",
    "### Data summary\n",
    "For this task our first step was to perform exporatory data analysis (EDA) and visualization.\n",
    "**train_dataset.describe()** shows a summary of the numerical training data.  The range of values for each feature appears to be valid. For example, the range for bpm is 62 to 199 with a mean and median close to 120bpm, which is considered to be optimal for song popularity.  **train_dataset.info()** shows that the target class top genre is 15 missing values (453-438). Non-Null counts should be equal, rows with missing top genre values were replace by predictions made by a Logistic Regression (LR) shown in a section below. LR was more accurate than using the mode or with an instance based model such as K Nearest Neighbors (KNN). Next **value_counts() and plt.bar()** revealed that there are 86 genres, only 1 or 2 examples for most genres, and that the dataset is very unbalanced which made learning from this dataset a challenge.  \n",
    "\n",
    "### Correlation\n",
    "Multicollinearity: independent variables are strongly correlated. This can reduce model performance. The variation inflation factor (VIF) for each variable can be computed. If predictive features yield VIF values less than 5, then this would indicate that multicollinearity is not a problem. However, the ***VIF*** output below shows that bpm and dnce are over 20!\n",
    "\n",
    "The correlation matrix below shows that dB and nrgy have the highest positively correlated features, val and dnce are second, while dnce and acoustics are the most negatively correlated. However, most of the features in this dataset have low correlation and, in fact, the application of PCA did not improve classification accuracy.\n",
    "\n",
    "### Outliers\n",
    "Next we used ***sns.boxplot()*** to reveal potential outliers. The default value for the whiskers is 1.5 standard deviations. The boxplots show that some features include data point far beyond the whiskers. While it's difficult to distinguish between significant data points and outliers (noise), we assumed that most values greater the 3 standard deviations from the mean were noise. \n",
    "\n",
    "### Clusters\n",
    "t-SNE can project higher dimensional data onto a 2D space such that points that are relatively close in high dimensional space are close in 2D space.  The t-SNE plot below indicates that the songs cluster in a nonrandom way and that there is structure in the data that may be exploited for classification.\n",
    "\n",
    "### What worked and what did not\n",
    "Most of the things we tried made either small incremetal improvement or none.  Dropping attributes (columns) usually reduced accuracy. PCA made little difference. Multiplying feature attributes or applying other mathmematical operations on features did not increase accuracy. But one-hot encoding title, artist, and year had a big positive impact on classification accuracy. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary of numerical features\n",
    "train_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature names and their counts, Non-Null counts should be equal.\n",
    "# top genre is the target (class) and has missing values (453-438)\n",
    "train_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of song genres\n",
    "There are too many classes (86) and not enough examples. Most classes have only 1 or 2 examples, while three classes have over 60 examples each. RandomOverSampling tried but not effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all = train_dataset[\"top genre\"]\n",
    "value_counts=y_all.value_counts()\n",
    "print(\"number of class names:\", len(value_counts)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[x for x in range(1,87)]\n",
    "# full training set is very unbalanced, \n",
    "# most genres have only 1 or 2 examples\n",
    "plt.figure(figsize=(20,3)) \n",
    "value_counts.hist(bins=86); \n",
    "plt.bar(x, value_counts.values);\n",
    "#plt.xticks(rotation=90);\n",
    "plt.xlabel('classes')\n",
    "plt.ylabel('count');\n",
    "plt.title('top genre');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot linear correlation matrix\n",
    "cm=train_dataset.iloc[:,0:14].corr()   # make sure indices are right!\n",
    "#cm[cm<0.45]=0\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9,3))\n",
    "sns.heatmap(cm, annot=True, cmap='YlGnBu', vmin=-1,\n",
    "vmax=1, center=0, ax=ax)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VIF\n",
    "\n",
    "We calculated the variance inflation factor for each feature. The VIF is given by: **VIF = 1/(1-R^2)** where R^2 is the coefficient of determination. In general, if a feature that has a VIF value greater than 5 is considered to be highly collinear with other features in the data.  The output below shows that bpm and dnce are over 20!  We found that dropping dnce or bpm reduced classification accuracy. This was surprising and could be future work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "num_data=train_dataset.iloc[:,4:14].copy()   # if this fails, the indices are wrong\n",
    "VIF             = pd.DataFrame()\n",
    "VIF['feature']  = num_data.columns\n",
    "VIF['VIF']      = [variance_inflation_factor(num_data.values, i) \\\n",
    "                   for i in range(num_data.shape[1])]\n",
    "VIF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplots show outliers\n",
    "Potential outliers (> 3 deviations) will be  removed in some cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# boxplots: visualize data distributions and outliers\n",
    "plt.figure(figsize=(7,5));\n",
    "df=train_dataset.drop(\"top genre\", axis=1, inplace=False)\n",
    "attributes=df.columns.values.tolist()\n",
    "idx=4\n",
    "for attribute in attributes[idx:]:\n",
    "    plt.subplot(5,3,idx)\n",
    "    sns.boxplot(x=train_dataset[attribute])\n",
    "    idx=idx+1\n",
    "    plt.tight_layout(pad=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNE shows some clustering in the training data\n",
    "The cluster are not sherical, but there appears to be structure in this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster data points using t-SNE\n",
    "show_legend=False\n",
    "# visualize training data\n",
    "temp_data=dataset.copy()\n",
    "df = pd.DataFrame()\n",
    "df[\"y\"] = temp_data['top genre'].copy();\n",
    "#temp_data.dropna(axis=0, inplace=True)\n",
    "temp_data.drop(['Id','title','artist', 'top genre'], axis=1, inplace=True)\n",
    "\n",
    "y_genre=df[\"y\"].sort_values(ascending=False)\n",
    "y_num = [ ii for ii in range(1, len(y_genre)+1)]\n",
    "\n",
    "X_train_embedded = TSNE(n_components=2, learning_rate='auto',\n",
    "                init='random', perplexity=3).fit_transform(temp_data)\n",
    "X_train_embedded.shape\n",
    "\n",
    "df[\"comp-1\"] = X_train_embedded[:,0]\n",
    "df[\"comp-2\"] = X_train_embedded[:,1]\n",
    "n_colors=len(df[\"y\"].unique())          # must be after drop NA\n",
    "plt.figure(figsize=(5,4));\n",
    "T=sns.scatterplot(x=\"comp-1\", y=\"comp-2\", color='b', legend=show_legend,\\\n",
    "                palette=sns.color_palette(\"rocket\", n_colors), \\\n",
    "                data=df, alpha=.9);\n",
    "plt.title('t-SNE projection of song numeric data ', fontsize=10)\n",
    "\n",
    "if show_legend:\n",
    "    plt.legend(bbox_to_anchor=(1.4, 1), loc='upper right', borderaxespad=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "828dbf91-fffd-4652-915b-7e755040f568",
    "_uuid": "17675bef-88d5-419c-81b0-72b4d6007789",
    "id": "xMsIp9ZIw1YP"
   },
   "source": [
    "# Data Pre-processing Steps on Train Set\n",
    "\n",
    "In this section, we applied data cleaning, feature selection, and feature engineering methods.\n",
    "\n",
    "***Cleaning***: Rows with missing values and outliers (z score > three std) were dropped.\n",
    "One duplicate row was dropped.  \n",
    "***Feature selection***: The \"Id\" column was dropped (it's not a feature). The \"pop\" (popularity) feature column was dropped ... \"pop\" was not predictive of top genre.  \n",
    "***Feature engineering***: The text features \"title\", \"artist\", and \"top genre\" were one-hot encoded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we  one-hot encode the title, year, and artist name categorical features on the theory that they contain information revelavnt to a song's genre. Intuitively, we suspected that artist would be strongly associated with genre and predictive. However, song title was not expected to help. Nonetheless, would found that one-hot encoding all three improved classifcation accuaracy on validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ac06be9d-fa91-4207-8f9a-fad927fb04bd",
    "_uuid": "ed98282c-ae1d-4eb3-b9ea-6bd8a07a695f",
    "execution": {
     "iopub.execute_input": "2023-02-18T21:57:13.072681Z",
     "iopub.status.busy": "2023-02-18T21:57:13.072262Z",
     "iopub.status.idle": "2023-02-18T21:57:13.099392Z",
     "shell.execute_reply": "2023-02-18T21:57:13.097954Z",
     "shell.execute_reply.started": "2023-02-18T21:57:13.072649Z"
    },
    "id": "1uPSnE34w1YQ",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#drop the popularity of the song since it has no direct contribution \n",
    "#in predicting top genre\n",
    "dataset = dataset.drop([\"Id\",\"pop\"], axis=1)\n",
    "#dropping the pop column for test set\n",
    "test_dataset = test_dataset.drop([\"Id\",\"pop\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T21:57:13.101246Z",
     "iopub.status.busy": "2023-02-18T21:57:13.100901Z",
     "iopub.status.idle": "2023-02-18T21:57:13.113206Z",
     "shell.execute_reply": "2023-02-18T21:57:13.112192Z",
     "shell.execute_reply.started": "2023-02-18T21:57:13.101215Z"
    },
    "id": "E2523XAgw1YR"
   },
   "outputs": [],
   "source": [
    "#copy of the original dataset\n",
    "train_dataset = dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T21:57:13.115587Z",
     "iopub.status.busy": "2023-02-18T21:57:13.114903Z",
     "iopub.status.idle": "2023-02-18T21:57:13.130450Z",
     "shell.execute_reply": "2023-02-18T21:57:13.129183Z",
     "shell.execute_reply.started": "2023-02-18T21:57:13.115544Z"
    },
    "id": "lGaY8YTqw1YS"
   },
   "outputs": [],
   "source": [
    "#create top genre in the test dataset\n",
    "c = \"top genre\"\n",
    "test_dataset = test_dataset.assign(**{c: pd.Series(dtype='object')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T21:57:13.132888Z",
     "iopub.status.busy": "2023-02-18T21:57:13.131880Z",
     "iopub.status.idle": "2023-02-18T21:57:13.145749Z",
     "shell.execute_reply": "2023-02-18T21:57:13.144685Z",
     "shell.execute_reply.started": "2023-02-18T21:57:13.132853Z"
    },
    "id": "eRMBlDP_w1YS"
   },
   "outputs": [],
   "source": [
    "#concating the train and test dataset\n",
    "concatenated_dataset = pd.concat([dataset, test_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T21:57:13.148174Z",
     "iopub.status.busy": "2023-02-18T21:57:13.147714Z",
     "iopub.status.idle": "2023-02-18T21:57:13.156432Z",
     "shell.execute_reply": "2023-02-18T21:57:13.155229Z",
     "shell.execute_reply.started": "2023-02-18T21:57:13.148132Z"
    },
    "id": "HaG1dAyiw1YT"
   },
   "outputs": [],
   "source": [
    "#give the same column name as the original dataset \n",
    "concatenated_dataset = concatenated_dataset.reset_index(drop=True)\n",
    "concatenated_dataset.columns= train_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "execution": {
     "iopub.execute_input": "2023-02-18T21:57:13.158762Z",
     "iopub.status.busy": "2023-02-18T21:57:13.157805Z",
     "iopub.status.idle": "2023-02-18T21:57:13.189051Z",
     "shell.execute_reply": "2023-02-18T21:57:13.187956Z",
     "shell.execute_reply.started": "2023-02-18T21:57:13.158729Z"
    },
    "id": "3ydcT4rvw1YU",
    "outputId": "7be644b9-7c69-4933-a2a8-5c936572ab97"
   },
   "outputs": [],
   "source": [
    "#concatenated_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T21:57:13.194190Z",
     "iopub.status.busy": "2023-02-18T21:57:13.193837Z",
     "iopub.status.idle": "2023-02-18T21:57:13.199928Z",
     "shell.execute_reply": "2023-02-18T21:57:13.198679Z",
     "shell.execute_reply.started": "2023-02-18T21:57:13.194158Z"
    },
    "id": "ziEteQ0mw1YU"
   },
   "outputs": [],
   "source": [
    "#dividing the dataset into dependable and independent variables\n",
    "x_con_data=concatenated_dataset.iloc[:,:-1]\n",
    "y_con_data=concatenated_dataset.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "dcdbe342-6f49-449d-95f2-ecb3a3a2eb33",
    "_uuid": "3d643c48-9a9e-4595-9f06-dc2a1c1a2730",
    "execution": {
     "iopub.execute_input": "2023-02-18T21:57:13.202333Z",
     "iopub.status.busy": "2023-02-18T21:57:13.201665Z",
     "iopub.status.idle": "2023-02-18T21:57:13.226666Z",
     "shell.execute_reply": "2023-02-18T21:57:13.225810Z",
     "shell.execute_reply.started": "2023-02-18T21:57:13.202289Z"
    },
    "id": "WIc1TdEuw1YV",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "# select the categorical variables\n",
    "categorical_variables = ['title','artist','year']\n",
    "\n",
    "# perform one hot encoding\n",
    "x_con_data = pd.get_dummies(x_con_data, columns=categorical_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T21:57:13.228392Z",
     "iopub.status.busy": "2023-02-18T21:57:13.227881Z",
     "iopub.status.idle": "2023-02-18T21:57:13.232957Z",
     "shell.execute_reply": "2023-02-18T21:57:13.232185Z",
     "shell.execute_reply.started": "2023-02-18T21:57:13.228348Z"
    },
    "id": "yMcOGP0hw1YV"
   },
   "outputs": [],
   "source": [
    "#adding the top genre in the one hot encoded dataset\n",
    "x_con_data['top genre'] = y_con_data\n",
    "#assigning the data to the variable concatenated data\n",
    "concatenated_dataset = x_con_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "execution": {
     "iopub.execute_input": "2023-02-18T21:57:13.234517Z",
     "iopub.status.busy": "2023-02-18T21:57:13.234131Z",
     "iopub.status.idle": "2023-02-18T21:57:13.266139Z",
     "shell.execute_reply": "2023-02-18T21:57:13.265284Z",
     "shell.execute_reply.started": "2023-02-18T21:57:13.234485Z"
    },
    "id": "prn8eKivw1YV",
    "outputId": "282e1f71-81a0-4fa5-c806-6a1de072a3a8"
   },
   "outputs": [],
   "source": [
    "#concatenated_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-02-18T21:57:13.267885Z",
     "iopub.status.busy": "2023-02-18T21:57:13.267398Z",
     "iopub.status.idle": "2023-02-18T21:57:13.274145Z",
     "shell.execute_reply": "2023-02-18T21:57:13.273225Z",
     "shell.execute_reply.started": "2023-02-18T21:57:13.267854Z"
    },
    "id": "w5iNzwvlw1YW",
    "outputId": "91e75c96-2e64-4094-a024-1bb4ebfbd98a"
   },
   "outputs": [],
   "source": [
    "# Manually specify the row index to split the dataset\n",
    "split_index = 453\n",
    "\n",
    "# Split the dataset into two parts\n",
    "dataset = concatenated_dataset.iloc[:split_index]\n",
    "test_dataset = concatenated_dataset.iloc[split_index:]\n",
    "\n",
    "# Print the size of the training and testing datasets\n",
    "print(f\"Training dataset size: {np.shape(dataset)}\")\n",
    "print(f\"Testing dataset size: {np.shape(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "548809bb-d107-4b72-a74d-92aa74252949",
    "_uuid": "15170bf5-9241-4b06-a9b3-ee6aa4347550",
    "execution": {
     "iopub.execute_input": "2023-02-18T21:57:13.334935Z",
     "iopub.status.busy": "2023-02-18T21:57:13.334462Z",
     "iopub.status.idle": "2023-02-18T21:57:13.341862Z",
     "shell.execute_reply": "2023-02-18T21:57:13.340650Z",
     "shell.execute_reply.started": "2023-02-18T21:57:13.334886Z"
    },
    "id": "ykSOf0x_w1YX",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# #copy of the original dataset\n",
    "train_dataset = dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "685526f8-1b1e-4c2f-be24-4e069ee4b2db",
    "_uuid": "b9e01c87-d744-4b2d-8232-8ff6177cb6b5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-02-18T21:57:13.344746Z",
     "iopub.status.busy": "2023-02-18T21:57:13.344149Z",
     "iopub.status.idle": "2023-02-18T21:57:13.364743Z",
     "shell.execute_reply": "2023-02-18T21:57:13.363745Z",
     "shell.execute_reply.started": "2023-02-18T21:57:13.344701Z"
    },
    "id": "42jb5ufUw1YX",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "e4065149-6fb0-41dd-9202-1cab5c7679a7"
   },
   "outputs": [],
   "source": [
    "#checking for null values in each columns in the dataset\n",
    "print(sum(dataset.iloc[:,:-1].isnull().any()))\n",
    "print(dataset.iloc[:,-1].isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a0703f75-0f32-4624-bbe2-cadec4234ec6",
    "_uuid": "dcecc364-c16e-42ad-a011-e97d301b47ef",
    "execution": {
     "iopub.execute_input": "2023-02-18T21:57:13.366792Z",
     "iopub.status.busy": "2023-02-18T21:57:13.365932Z",
     "iopub.status.idle": "2023-02-18T21:57:13.872105Z",
     "shell.execute_reply": "2023-02-18T21:57:13.871197Z",
     "shell.execute_reply.started": "2023-02-18T21:57:13.366758Z"
    },
    "id": "Iasr1x7cw1YX",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Create a boolean mask of rows with missing values\n",
    "mask = dataset.isnull().any(axis=1)\n",
    "\n",
    "# Split the data into two sets: with and without missing values\n",
    "test_set = dataset[mask]\n",
    "train_set = dataset[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "49cc1d76-f5df-45bc-97f1-54774691e7b3",
    "_uuid": "1639fb3f-31b5-4302-8ece-f5f83fcc1391",
    "execution": {
     "iopub.execute_input": "2023-02-18T21:57:13.873712Z",
     "iopub.status.busy": "2023-02-18T21:57:13.873398Z",
     "iopub.status.idle": "2023-02-18T21:57:13.882836Z",
     "shell.execute_reply": "2023-02-18T21:57:13.881785Z",
     "shell.execute_reply.started": "2023-02-18T21:57:13.873684Z"
    },
    "id": "0YkhVPpFw1YX",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Split the set without missing values into training and test sets\n",
    "x_train = train_set.drop(\"top genre\",axis=1)\n",
    "y_train = train_set[\"top genre\"]\n",
    "x_test = test_set.drop(\"top genre\",axis=1)\n",
    "y_test = test_set[\"top genre\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1eb54fdb-70d1-4504-b1f8-e641d6b016e2",
    "_uuid": "414ed41a-b174-4936-bf76-0798df41487b",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-02-18T21:57:13.884597Z",
     "iopub.status.busy": "2023-02-18T21:57:13.884162Z",
     "iopub.status.idle": "2023-02-18T21:57:13.899892Z",
     "shell.execute_reply": "2023-02-18T21:57:13.898668Z",
     "shell.execute_reply.started": "2023-02-18T21:57:13.884555Z"
    },
    "id": "M6FInWItw1YY",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "5f4843cc-aa14-449d-c39c-42c0d0f4c936"
   },
   "outputs": [],
   "source": [
    "#checking for null values in x_train and y_train\n",
    "\n",
    "print(sum(x_train.isnull().any()))\n",
    "print(y_train.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "eb9b05c5-1656-462b-90dc-ccf7625fb749",
    "_uuid": "2734d306-b42c-4708-8c80-1f2a6478c021",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-02-18T21:57:13.902260Z",
     "iopub.status.busy": "2023-02-18T21:57:13.901797Z",
     "iopub.status.idle": "2023-02-18T21:57:13.915562Z",
     "shell.execute_reply": "2023-02-18T21:57:13.914441Z",
     "shell.execute_reply.started": "2023-02-18T21:57:13.902214Z"
    },
    "id": "Lq5lODlPw1YY",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "47da56ca-3683-4c77-93b4-bf8ca553d69d"
   },
   "outputs": [],
   "source": [
    "#checking for null values in x_test and y_test\n",
    "\n",
    "print(sum(x_test.isnull().any()))\n",
    "print(y_test.isnull().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace missing top genre values with predicted genres\n",
    "We used Logistic Regression to replace missing top genre values instead of KNN or dropping those rows. This was the most accurate method and it preserved the useful information contained in those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T21:57:13.973258Z",
     "iopub.status.busy": "2023-02-18T21:57:13.972912Z",
     "iopub.status.idle": "2023-02-18T21:57:13.984438Z",
     "shell.execute_reply": "2023-02-18T21:57:13.983434Z",
     "shell.execute_reply.started": "2023-02-18T21:57:13.973225Z"
    },
    "id": "bHAEOc7dw1YZ"
   },
   "outputs": [],
   "source": [
    "#feature scaling of the training data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "x_train=x_train.values\n",
    "x_test=x_test.values\n",
    "# Scale the input data\n",
    "scaler = StandardScaler()\n",
    "x_train[:,:9] = scaler.fit_transform(x_train[:,:9])\n",
    "x_test[:,:9] = scaler.transform(x_test[:,:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-02-18T21:57:13.986485Z",
     "iopub.status.busy": "2023-02-18T21:57:13.985806Z",
     "iopub.status.idle": "2023-02-18T21:57:18.336792Z",
     "shell.execute_reply": "2023-02-18T21:57:18.335219Z",
     "shell.execute_reply.started": "2023-02-18T21:57:13.986452Z"
    },
    "id": "FzSomuBSw1YZ",
    "outputId": "db49e97f-11c2-432c-cd86-c0aa4df49a11"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameters and search space\n",
    "params = {\"C\": [100], \"penalty\": [\"l1\"], \"solver\": [\"liblinear\"],\"max_iter\": [1000]}\n",
    "\n",
    "# Create the logistic regression model\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Perform a grid search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=lr, param_grid=params, cv=5)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the testing dataset\n",
    "y_test = grid_search.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5aa0ab74-f565-4168-b9d0-7abd8c9b891d",
    "_uuid": "7be7d6ee-b52a-4dd6-bb77-7856cd5a6b20",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-02-18T21:57:18.340827Z",
     "iopub.status.busy": "2023-02-18T21:57:18.339198Z",
     "iopub.status.idle": "2023-02-18T21:57:18.352252Z",
     "shell.execute_reply": "2023-02-18T21:57:18.350433Z",
     "shell.execute_reply.started": "2023-02-18T21:57:18.340759Z"
    },
    "id": "2iCzywyHw1YZ",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "cb9d67b5-2a57-4f14-cb7f-457783573e49"
   },
   "outputs": [],
   "source": [
    "#printing the predicted values of y_test\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7dbb0eaf-e550-489b-8ff9-fd63d1bec581",
    "_uuid": "3daced6c-e452-430b-a6b2-e49a0760de28",
    "execution": {
     "iopub.execute_input": "2023-02-18T21:57:18.355415Z",
     "iopub.status.busy": "2023-02-18T21:57:18.354739Z",
     "iopub.status.idle": "2023-02-18T21:57:18.368370Z",
     "shell.execute_reply": "2023-02-18T21:57:18.366423Z",
     "shell.execute_reply.started": "2023-02-18T21:57:18.355342Z"
    },
    "id": "iqdltw5Kw1Ya",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Concatenate x_train and x_test along axis 0\n",
    "x = np.concatenate((x_train, x_test), axis=0)\n",
    "# Concatenate y_train and y_test along axis 0\n",
    "y = np.concatenate((y_train, y_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "149177d9-5afd-4202-ad8e-b649a5339d58",
    "_uuid": "26759808-69d8-49f3-88ce-9ba7ea090688",
    "execution": {
     "iopub.execute_input": "2023-02-18T21:57:18.372879Z",
     "iopub.status.busy": "2023-02-18T21:57:18.371626Z",
     "iopub.status.idle": "2023-02-18T21:57:18.403527Z",
     "shell.execute_reply": "2023-02-18T21:57:18.401863Z",
     "shell.execute_reply.started": "2023-02-18T21:57:18.372819Z"
    },
    "id": "HYfpmV1ew1Ya",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Convert x_train and y_train to data frames\n",
    "x = pd.DataFrame(x)\n",
    "y = pd.DataFrame(y)\n",
    "\n",
    "# Merge x_train and y_train along axis 1 (i.e., horizontally)\n",
    "dataset = pd.concat([x ,y], axis=1)\n",
    "dataset = dataset.reset_index(drop=True)\n",
    "dataset.columns= train_dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect duplicate rows and delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7c97709e-e333-41a6-99c4-038f3dca6c94",
    "_uuid": "53bed81b-333e-457a-abb5-10d223075230",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-02-18T21:57:18.450963Z",
     "iopub.status.busy": "2023-02-18T21:57:18.450267Z",
     "iopub.status.idle": "2023-02-18T21:57:18.670113Z",
     "shell.execute_reply": "2023-02-18T21:57:18.668884Z",
     "shell.execute_reply.started": "2023-02-18T21:57:18.450920Z"
    },
    "id": "ia5u00iVw1Ya",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "b3b19b51-0880-49ea-e0c8-08d1e16b8649"
   },
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicates = dataset.duplicated().sum()\n",
    "print(f\"Number of duplicates: {duplicates}\")\n",
    "dataset = dataset.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete rows that contain one or more outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "99248fc7-08b4-4594-8857-a307a825a411",
    "_uuid": "be2970aa-7afb-45de-939c-474a5af91fbc",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-02-18T21:57:18.672425Z",
     "iopub.status.busy": "2023-02-18T21:57:18.671789Z",
     "iopub.status.idle": "2023-02-18T21:57:18.710598Z",
     "shell.execute_reply": "2023-02-18T21:57:18.709198Z",
     "shell.execute_reply.started": "2023-02-18T21:57:18.672386Z"
    },
    "id": "2Bmx3lcxw1Ya",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "84e4981d-af09-4d19-8c09-f7c2d4c1d505"
   },
   "outputs": [],
   "source": [
    "# Define function to handle outliers using z-score method\n",
    "def handle_outliers_z_score(df, threshold=3):\n",
    "    z_scores = np.abs((df - df.mean()) / df.std())\n",
    "    df_out = df[(z_scores < threshold).all(axis=1)]\n",
    "    return df_out\n",
    "\n",
    "# Apply function to relevant columns\n",
    "outliers_dataset = dataset.copy()\n",
    "columns = ['bpm', 'nrgy', 'dnce', 'dB', 'live', 'val', 'dur', 'acous', 'spch']\n",
    "df_outliers_removed = handle_outliers_z_score(outliers_dataset[columns])\n",
    "dataset = pd.concat([df_outliers_removed, dataset.drop(columns, axis=1) ], axis=1)\n",
    "dataset = dataset.dropna()\n",
    "\n",
    "# Print number of rows before and after handling outliers\n",
    "print(f\"Original number of rows: {len(outliers_dataset)}\")\n",
    "print(f\"Number of rows after handling outliers: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition the training set into training examples and their class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "44981ba2-0625-44e2-bbe3-e781b98011c4",
    "_uuid": "bfd38557-69e8-4799-8d67-fdafd5d372e4",
    "execution": {
     "iopub.execute_input": "2023-02-18T21:57:18.751954Z",
     "iopub.status.busy": "2023-02-18T21:57:18.751006Z",
     "iopub.status.idle": "2023-02-18T21:57:18.759352Z",
     "shell.execute_reply": "2023-02-18T21:57:18.758280Z",
     "shell.execute_reply.started": "2023-02-18T21:57:18.751908Z"
    },
    "id": "AkF_WiOjw1Yb",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#dividing the dataset into dependable and independent variables\n",
    "X_train=dataset.iloc[:,:-1]\n",
    "Y_train=dataset.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Classifier Models\n",
    "\n",
    "In this section we trained the Logistic Regression (LR), Support Vector Classifier (SVC), K Nearest Neighbors (KNN), and RandomForestClassifier (RFC) models on the training data. LR is a relatively simple and easy to use model that we expected to use it as a benchmark. The SVC is more suitable for complex data and we expected it to deliver better accuracy than LR.  KNN was selected because the t-SNE plot indicated that the songs cluster in a nonrandom way. Essentially, t-SNE projects higher dimensional data onto a 2D space such that points that are relatively close in high dimensional space are close in 2D space.\n",
    "\n",
    "We used GridSearchCV to find the best hyperparameters and perform cross validation to identify the best model.   \n",
    "See plots below.  \n",
    "\n",
    "One interesting result was that LR delivered 100% accuracy on the training set.  Logistic regression is considered a generalized linear model because its output depends on the sum of inputs and parameters, and not on the product or quotient, etc., of those parameters. So the training partitions processed by GridSearchCV were linearly separable. Possibly thanks to one-hot encoding. Best Kaggle score was **0.53571** with hyperparameter C=91 (C=1 is the default).  So LR worked best with weak regularization.  Training accuracy ramped up very quickly, but validation accuracy improved very slowly.\n",
    "\n",
    "Note: C is a postive float and the inverse of regularization strength. It's similar to the C hyperparameter used by support vector machines.  Smaller values result in stronger regularization.\n",
    "\n",
    "SVC validation set accuracy increased steadily with increasing C, optimal C was ~1.6, but accuracy of ~0.37 was a distant second to LR.\n",
    "\n",
    "The KNN plot is interesting because as K increases accuracy decrease. Of course the nearest neighbor to an instance is itself and as K increases more distant neighbors and disimilar neighbors are included in the vote. Optimal K was 8 which got an accuracy of ~0.34. This confirmed the t-SNE result during EDA that suggested there are some clusters in this dataset.\n",
    "\n",
    "Validation accuracy of the models was mostly in the 30% to 50% range.\n",
    "\n",
    "After selecting the best model based on accuracy on validation data before running the model on the unseen test data for submission to Kaggle. While no Kaggle test data was used for training there was a risk that some test data information \"leaked\" into the training data because each Kaggle score could be used as feedback and influence model training decisions.\n",
    "\n",
    "### Summary of final results\n",
    "Ultimately the Logistic Regression model got our best score on Kaggle: ***0.53571***.  random_state not set at the time, so it's only almost reproducible.  Straw-hat Pirates are 11th on the Kaggle leaderboard.\n",
    "#### LR_model = LogisticRegression(C=91, max_iter=1000, penalty='l1', solver='liblinear', random_state);\n",
    "#### SVC_model = SVC(C=1.6,  gamma='scale', kernel='sigmoid',  random_state=42);\n",
    "#### RFC_model = RandomForestClassifier(n_estimators=400, max_depth=14, random_state=42)\n",
    "#### KNN_model = KNeighborsClassifier(n_neighbors=8,  weights='uniform', random_state=42);\n",
    "\n",
    "\n",
    "Typical and reprodicible results are shown in this table and the plots below.\n",
    "\n",
    "| Model | Train Acc | Validation Acc |\n",
    "| --- | --- | --- |\n",
    "| Logistic Regression | 1.0 | 0.528 |\n",
    "| SVC             | 0.519 | 0.371 |\n",
    "| Random Forest   | 0.619   |  0.396  |\n",
    "| KNN            |  0.625   | 0.344   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BOZKKjf6w1Yc"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-02-18T21:57:20.128792Z",
     "iopub.status.busy": "2023-02-18T21:57:20.128002Z",
     "iopub.status.idle": "2023-02-18T21:57:21.085054Z",
     "shell.execute_reply": "2023-02-18T21:57:21.083448Z",
     "shell.execute_reply.started": "2023-02-18T21:57:20.128735Z"
    },
    "id": "6LF_ktMqw1Yc",
    "outputId": "96392589-3df1-46db-e499-48b873852193"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "C=np.arange(1,110,10)\n",
    "\n",
    "# Define the hyperparameters and search space\n",
    "params = {\"C\": C, \"penalty\": [\"l1\"], \"solver\": [\"liblinear\"],\"max_iter\": [1000]}\n",
    "\n",
    "# Create the logistic regression model\n",
    "lr = LogisticRegression(random_state=42)\n",
    "\n",
    "# Perform a grid search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=lr, param_grid=params, cv=5,\\\n",
    "                           return_train_score=True)\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# Find the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "mean_train = grid_search.cv_results_['mean_train_score']\n",
    "mean_val =   grid_search.cv_results_['mean_test_score']\n",
    "\n",
    "print(\"mean weighted train scores={}\".format(mean_train))\n",
    "print(\"mean weighted validation scores={}\".format(mean_val))\n",
    "print(\"best validation score={}\".format(best_score))\n",
    "#val acc -> 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(9,3))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(C, mean_train, label=\"train\")\n",
    "plt.plot(C, mean_val, label=\"validation\")\n",
    "plt.title(\"Logistic Regression\")\n",
    "plt.ylabel(\"mean accuracy\")\n",
    "plt.xlabel(\"C\")\n",
    "plt.xticks(C)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_model = LogisticRegression(C=91, max_iter=1000, penalty='l1', solver='liblinear', random_state=42);\n",
    "LR_model.fit(X_train, Y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "71d2423f-9a8b-4b1a-b5a5-8d9eef5ae621",
    "_uuid": "7c9c50b4-efc4-47e7-a68d-0276e9523852",
    "id": "2JE_Drxaw1Yb"
   },
   "source": [
    "## Support Vector Classifier (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "810429ae-2b75-4623-8b99-2e6ef44610a1",
    "_uuid": "0257f9e4-fd70-428c-bea1-c66d92557925",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-02-18T21:57:18.788241Z",
     "iopub.status.busy": "2023-02-18T21:57:18.787701Z",
     "iopub.status.idle": "2023-02-18T21:57:19.917816Z",
     "shell.execute_reply": "2023-02-18T21:57:19.916667Z",
     "shell.execute_reply.started": "2023-02-18T21:57:18.788092Z"
    },
    "id": "jPx0LzrFw1Yc",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "ee63b1e7-ad46-4512-d437-489dc19e02d6"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "# define the hyperparameter grid to search over\n",
    "C=np.arange(0.5, 2, 0.1)\n",
    "param_grid = {'C': C,'kernel': ['sigmoid'],'gamma': ['scale']}\n",
    "# create an SVM classifier\n",
    "svm_clf = SVC(random_state=42)\n",
    "svm_clf.fit(X_train,Y_train)\n",
    "# perform a grid search over the hyperparameter grid using cross-validation\n",
    "grid_search = GridSearchCV(estimator=svm_clf, param_grid=param_grid, cv=5,\\\n",
    "                           return_train_score=True)\n",
    "grid_search.fit(X_train, Y_train)\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(best_params)\n",
    "best_score = grid_search.best_score_\n",
    "mean_train = grid_search.cv_results_['mean_train_score']\n",
    "mean_val   = grid_search.cv_results_['mean_test_score']\n",
    "print(\"mean weighted train score={}\".format(mean_train))\n",
    "print(\"mean weighted validation score={}\".format(mean_val))\n",
    "print(\"best validation score={}\".format(best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_model = SVC(C=best_params['C'], kernel=best_params['kernel'], random_state=42);\n",
    "SVC_model.fit(X_train,Y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(9,3))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(C, mean_train, label=\"train\")\n",
    "plt.plot(C, mean_val, label=\"validation\")\n",
    "plt.title(\"Support Vector Classifier\")\n",
    "plt.ylabel(\"mean accuracy\")\n",
    "plt.xlabel(\"C\")\n",
    "plt.xticks(C)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# define a range of  values to search over\n",
    "#\n",
    "# param_grid = {'n_estimators': [50, 100, 200, 400, 800]}  # 400 best\n",
    "\n",
    "max_depth_vec=np.arange(1,16,1)\n",
    "param_grid = {'max_depth': max_depth_vec}\n",
    "\n",
    "# perform a grid search over the n_estimators values\n",
    "grid_search = GridSearchCV(rf_clf, param_grid, cv=5, return_train_score=True)\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "best_score=grid_search.best_score_\n",
    "\n",
    "mean_train = grid_search.cv_results_['mean_train_score']\n",
    "mean_val   = grid_search.cv_results_['mean_test_score']\n",
    "print(\"mean weighted train scores={}\".format(mean_train))\n",
    "print(\"mean weighted validation scores={}\".format(mean_val))\n",
    "\n",
    "# print the best n_estimators value and corresponding score\n",
    "print(\"Best max_depth: {}\".format(best_params['max_depth']))\n",
    "print(\"Best validation score: {:.2f}%\".format(best_score*100))\n",
    "\n",
    "# TEST ACCURACY -> 46.4%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC_model = RandomForestClassifier(n_estimators=400, max_depth=14, random_state=42)\n",
    "RFC_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(9,3))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(max_depth_vec, mean_train, label=\"train\")\n",
    "plt.plot(max_depth_vec, mean_val, label=\"validation\")\n",
    "plt.title(\"Random Forest Classifier\")\n",
    "plt.ylabel(\"mean accuracy\")\n",
    "plt.xlabel(\"max depth\")\n",
    "plt.xticks(max_depth_vec)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VcI9UgCXw1Yc"
   },
   "source": [
    "## K Nearest Neighbor (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-02-18T21:57:19.919709Z",
     "iopub.status.busy": "2023-02-18T21:57:19.919295Z",
     "iopub.status.idle": "2023-02-18T21:57:20.126084Z",
     "shell.execute_reply": "2023-02-18T21:57:20.124927Z",
     "shell.execute_reply.started": "2023-02-18T21:57:19.919679Z"
    },
    "id": "rFJsq42Jw1Yc",
    "outputId": "c5b1b5b7-ef46-48a6-bac5-9ae3c8fa0846"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Create an instance of KNN\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "K=np.arange(1,10,1)\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "param_grid = {'n_neighbors': K, 'weights': ['uniform']}\n",
    "\n",
    "# Use Grid Search to find the best hyperparameters using croo validation\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, return_train_score=True)\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(best_params)\n",
    "best_score=best_params = grid_search.best_params_\n",
    "\n",
    "mean_train = grid_search.cv_results_['mean_train_score']\n",
    "mean_val   = grid_search.cv_results_['mean_test_score']\n",
    "print(\"mean weighted train score={}\".format(mean_train))\n",
    "print(\"mean weighted validation score={}\".format(mean_val))\n",
    "print(\"best validation score score={}\".format(best_score))\n",
    "# val acc ~ 34%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a new KNN model with the best hyperparameters\n",
    "KNN_model = KNeighborsClassifier(n_neighbors=best_params['n_neighbors'],weights=best_params['weights']);\n",
    "KNN_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(9,3))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(K, mean_train, label=\"train\")\n",
    "plt.plot(K, mean_val, label=\"validation\")\n",
    "plt.title(\"KNN Classifier\")\n",
    "plt.ylabel(\"mean accuracy\")\n",
    "plt.xlabel(\"K\")\n",
    "plt.xticks(K)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4FbsjdFw1Yd"
   },
   "source": [
    "## predict: run the selected model on the Kaggle test set data\n",
    "After selecting the best model based on accuracy on validation data, run the model on the unseen test data, save predictions to a cvs file, and submit the csv file to Kaggle. And hopefully move up the leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T21:57:21.122469Z",
     "iopub.status.busy": "2023-02-18T21:57:21.117836Z",
     "iopub.status.idle": "2023-02-18T21:57:21.135499Z",
     "shell.execute_reply": "2023-02-18T21:57:21.133912Z",
     "shell.execute_reply.started": "2023-02-18T21:57:21.122388Z"
    },
    "id": "Qpc44ZyZw1Yd"
   },
   "outputs": [],
   "source": [
    "test_dataset = test_dataset.drop([\"top genre\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T21:57:21.147040Z",
     "iopub.status.busy": "2023-02-18T21:57:21.142976Z",
     "iopub.status.idle": "2023-02-18T21:57:21.159741Z",
     "shell.execute_reply": "2023-02-18T21:57:21.158137Z",
     "shell.execute_reply.started": "2023-02-18T21:57:21.146965Z"
    },
    "id": "58uXdz1Bw1Yd"
   },
   "outputs": [],
   "source": [
    "#feature scaling on test dataset\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X_train.iloc[:,:9])\n",
    "test_dataset_arr=test_dataset\n",
    "test_dataset_arr.iloc[:,:9]=scaler.transform(test_dataset_arr.iloc[:,:9]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T21:57:21.172657Z",
     "iopub.status.busy": "2023-02-18T21:57:21.168572Z",
     "iopub.status.idle": "2023-02-18T21:57:21.186451Z",
     "shell.execute_reply": "2023-02-18T21:57:21.184566Z",
     "shell.execute_reply.started": "2023-02-18T21:57:21.172582Z"
    },
    "id": "0lAj5XSmw1Yd"
   },
   "outputs": [],
   "source": [
    "# select model to test and automatically save predictions to csv file\n",
    "logistic_regression=True   # <<<<<<<<<<<<=========\n",
    "svc_classification=False\n",
    "knn_classification=False\n",
    "rf_classification=False\n",
    "Y_test_done=False\n",
    "\n",
    "if logistic_regression:\n",
    "    y_test_pred = LR_model.predict(test_dataset)\n",
    "    file_name=\"y_pred_lrc.csv\"\n",
    "    Y_test_done=True\n",
    "elif svc_classification:\n",
    "    y_test_pred = SVC_model.predict(test_dataset_arr)\n",
    "    file_name=\"y_pred_svc.csv\"\n",
    "    Y_test_done=True\n",
    "elif rf_classification:   \n",
    "    y_test_pred = RFC_model.predict(test_dataset_arr)\n",
    "    file_name=\"y_pred_rfc.csv\"\n",
    "    Y_test_done=True\n",
    "elif knn_classification:   \n",
    "    y_test_pred = KNN_model.predict(test_dataset_arr)\n",
    "    file_name=\"y_pred_knnc.csv\"\n",
    "    Y_test_done=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T21:57:21.096589Z",
     "iopub.status.busy": "2023-02-18T21:57:21.092602Z",
     "iopub.status.idle": "2023-02-18T21:57:21.110110Z",
     "shell.execute_reply": "2023-02-18T21:57:21.108512Z",
     "shell.execute_reply.started": "2023-02-18T21:57:21.096509Z"
    },
    "id": "ImQTHt1fHZda"
   },
   "outputs": [],
   "source": [
    "# save Kaggle test predictions to csv file \n",
    "def save_y_pred(X_TEST_Id, y_pred_test, file_name):\n",
    "  with open(file_name, 'w') as f:\n",
    "    f.write(\"Id,\" + \"top genre\\n\")\n",
    "    for ii in range(113):\n",
    "      f.write(str(X_TEST_Id[ii]) + \",\")\n",
    "      f.write(y_pred_test[ii]+\"\\n\")\n",
    "\n",
    "if Y_test_done:\n",
    "    TEST_Id= test_df.iloc[:,:1].values\n",
    "    TEST_Id=TEST_Id.flatten()\n",
    "    TEST_Id=list(TEST_Id)\n",
    "    y_test_pred=list(y_test_pred)\n",
    "    save_y_pred(TEST_Id, y_test_pred, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T21:57:21.259269Z",
     "iopub.status.busy": "2023-02-18T21:57:21.255326Z",
     "iopub.status.idle": "2023-02-18T21:57:21.273041Z",
     "shell.execute_reply": "2023-02-18T21:57:21.271198Z",
     "shell.execute_reply.started": "2023-02-18T21:57:21.259199Z"
    },
    "id": "5mllU7UfHekt"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
